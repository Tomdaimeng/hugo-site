+++
title = "ESL-1 序言"
summary = """
统计学习基础（译注）第一章，第 1 ～ 8 页。
"""

date = 2018-08-27T15:40:07+08:00
lastmod = 2018-08-27T15:40:07+08:00
draft = false
math = true

authors = ["Butters"]

tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

“统计学习”在自然科学、金融和实业界中的很多领域都起着关键的作用。
以下为一些具体应用场景：

- 预测一个由于心脏病入院治疗的病人是否会再次突发心脏病。
  这种预测基于这个病人的人口统计学特征、饮食和临床指标。
- 基于某家公司的基本面表现数据以及宏观经济数据，预测六个月之后该公司的股票价格。
- 从扫描数字化的手写邮政编码的图片中，识别出数字。
- 从一个糖尿病患者血液样本的红外吸收光谱，估计出这个人的血糖浓度。
- 基于临床指标和人口统计特征，识别（不同个体的）患前列腺癌症的风险程度。

Statistical learning plays a key role in many areas of science, finance and
industry. Here are some examples of learning problems:

- Predict whether a patient, hospitalized due to a heart attack, will
have a second heart attack. The prediction is to be based on demo-
graphic, diet and clinical measurements for that patient.
- Predict the price of a stock in 6 months from now, on the basis of
company performance measures and economic data.
- Identify the numbers in a handwritten ZIP code, from a digitized
image.
- Estimate the amount of glucose in the blood of a diabetic person,
from the infrared absorption spectrum of that person’s blood.
- Identify the risk factors for prostate cancer, based on clinical and
demographic variables.

在统计学、数据挖掘、人工智能以及与工程和其他学科的交叉领域中，关于“统计学习”的研究起到了关键作用。
本书着眼于从如何通过数据来学习。一个典型的场景中，我们有某个通常为量化（比如股票价格）或类别的（例如“是否突发心脏病”）目标指标，我们希望可以利用一组特征（例如饮食和临床指标）来预测目标指标。我们有一组“训练集”数据，从中我们可以研究一组样本（比如一群人）的目标指标与特征值。利用这组数据，我们建立一个预测模型（学习模型），我们可以使用这个模型对不在这组数据中的新样本的目标指标。一个好的学习模型应可以准确地预测目标值表。
上述场景即为所谓的“有监督学习”问题。称之为“有监督”，是因为训练集包含了已知的目标指标来指导模型的学习过程。在“无监督学习”问题中，我们只能观测到一组样本的特征，而没有目标指标。我们要做的是描述数据内部是如何关联和分类的。这本书的大部分是关于有监督学习的，无监督学习的领域相对还不成熟，主要在第14章介绍。

The science of learning plays a key role in the fields of statistics, data
mining and artificial intelligence, intersecting with areas of engineering and
other disciplines.
This book is about learning from data. In a typical scenario, we have
an outcome measurement, usually quantitative (such as a stock price) or
categorical (such as heart attack/no heart attack), that we wish to predict
based on a set of features (such as diet and clinical measurements). We
have a training set of data, in which we observe the outcome and feature
measurements for a set of objects (such as people). Using this data we build
a prediction model, or learner, which will enable us to predict the outcome
for new unseen objects. A good learner is one that accurately predicts such
an outcome.
The examples above describe what is called the supervised learning prob-
lem. It is called “supervised” because of the presence of the outcome vari-
able to guide the learning process. In the unsupervised learning problem,
we observe only the features and have no measurements of the outcome.
Our task is rather to describe how the data are organized or clustered. We
devote most of this book to supervised learning; the unsupervised problem
is less developed in the literature, and is the focus of Chapter 14.

以下给出本书中会持续讨论的几个真实的统计学习问题的例子。
Here are some examples of real learning problems that are discussed in
this book.


### 例一：骚扰邮件

这个例子所用的数据包括从 4601 封电子邮件中的信息，数据来自于尝试预测一封电子邮件是否为垃圾或骚扰邮件的研究。想要达成的目的是设计一个自动的垃圾骚扰邮件探测器，可以从用户的邮箱中自动过滤掉垃圾邮件。对所有的 4601 封电子邮件，我们有其是否为正常邮件或垃圾邮件的真实标签，同时也有 57 个最经常出现的单词和标点符号的相对出现频率。这是一个有监督学习问题，目标变量为二分类的变量（正常邮件/垃圾邮件）。这种也被称为分类问题。
表1.1 列出了正常邮件和垃圾邮件中的平均出现相对频率差别最大的词。相对出现频率为这个词在这个邮件中出现的次数与这个邮件所有词个数的比率。
我们的学习器须要确定用哪些特征和如何用这些特征。例如，我们可以制定规则：
如果

在此例子中，并不是所有分类错误都有相同的后果。我们要尽量避免过滤掉正常邮件，于此同时放过一些垃圾邮件是相对可以接受的。在此书中会介绍解决这个问题的不同方法。




Example 1: Email Spam

The data for this example consists of information from 4601 email mes-
sages, in a study to try to predict whether the email was junk email, or
“spam.” The objective was to design an automatic spam detector that
could filter out spam before clogging the users’ mailboxes. For all 4601
email messages, the true outcome (email type) email or spam is available,
along with the relative frequencies of 57 of the most commonly occurring
words and punctuation marks in the email message. This is a supervised
learning problem, with the outcome the class variable email / spam . It is also
called a classification problem.
Table 1.1 lists the words and characters showing the largest average
difference between spam and email .
Our learning method has to decide which features to use and how: for
example, we might use a rule such as

if ( %george < 0.6) & ( %you > 1.5)
then spam
else email .

Another form of a rule might be:

if (0.2 · %you − 0.3 · %george ) > 0
then spam
else email .

For this problem not all errors are equal; we want to avoid filtering out
good email, while letting spam get through is not desirable but less serious
in its consequences. We discuss a number of different methods for tackling
this learning problem in the book.

### 例二：前列腺癌症



Example 2: Prostate Cancer

The data for this example, displayed in Figure 1.1 1 , come from a study
by Stamey et al. (1989) that examined the correlation between the level of
prostate specific antigen (PSA) and a number of clinical measures, in 97
men who were about to receive a radical prostatectomy.
The goal is to predict the log of PSA ( lpsa ) from a number of measure-
ments including log cancer volume ( lcavol ), log prostate weight lweight ,
age, log of benign prostatic hyperplasia amount lbph , seminal vesicle in-
vasion svi , log of capsular penetration lcp , Gleason score gleason , and
percent of Gleason scores 4 or 5 pgg45 . Figure 1.1 is a scatterplot matrix
of the variables. Some correlations with lpsa are evident, but a good pre-
dictive model is difficult to construct by eye.
This is a supervised learning problem, known as a regression problem,
because the outcome measurement is quantitative.

### 例三：手写数字识别


Example 3: Handwritten Digit Recognition

The data from this example come from the handwritten ZIP codes on
envelopes from U.S. postal mail. Each image is a segment from a five digit
ZIP code, isolating a single digit. The images are 16×16 eight-bit grayscale
maps, with each pixel ranging in intensity from 0 to 255. Some sample
images are shown in Figure 1.2.
The images have been normalized to have approximately the same size
and orientation. The task is to predict, from the 16 × 16 matrix of pixel
intensities, the identity of each image (0, 1, . . . , 9) quickly and accurately. If
it is accurate enough, the resulting algorithm would be used as part of an
automatic sorting procedure for envelopes. This is a classification problem
for which the error rate needs to be kept very low to avoid misdirection of
mail. In order to achieve this low error rate, some objects can be assigned
to a “don’t know” category, and sorted instead by hand.

### 例四：DNA表达序列


Example 4: DNA Expression Microarrays

DNA stands for deoxyribonucleic acid, and is the basic material that makes
up human chromosomes. DNA microarrays measure the expression of a
gene in a cell by measuring the amount of mRNA (messenger ribonucleic
acid) present for that gene. Microarrays are considered a breakthrough
technology in biology, facilitating the quantitative study of thousands of
genes simultaneously from a single sample of cells.
Here is how a DNA microarray works. The nucleotide sequences for a few
thousand genes are printed on a glass slide. A target sample and a reference
sample are labeled with red and green dyes, and each are hybridized with
the DNA on the slide. Through fluoroscopy, the log (red/green) intensities
of RNA hybridizing at each site is measured. The result is a few thousand
numbers, typically ranging from say −6 to 6, measuring the expression level
of each gene in the target relative to the reference sample. Positive values
indicate higher expression in the target versus the reference, and vice versa
for negative values.
A gene expression dataset collects together the expression values from a
series of DNA microarray experiments, with each column representing an
experiment. There are therefore several thousand rows representing individ-
ual genes, and tens of columns representing samples: in the particular ex-
ample of Figure 1.3 there are 6830 genes (rows) and 64 samples (columns),
although for clarity only a random sample of 100 rows are shown. The fig-
ure displays the data set as a heat map, ranging from green (negative) to
red (positive). The samples are 64 cancer tumors from different patients.
The challenge here is to understand how the genes and samples are or-
ganized. Typical questions include the following:
(a) which samples are most similar to each other, in terms of their expres-
sion profiles across genes?
(b) which genes are most similar to each other, in terms of their expression
profiles across samples?
(c) do certain genes show very high (or low) expression for certain cancer
samples?

We could view this task as a regression problem, with two categorical
predictor variables—genes and samples—with the response variable being
the level of expression. However, it is probably more useful to view it as
unsupervised learning problem. For example, for question (a) above, we
think of the samples as points in 6830–dimensional space, which we want
to cluster together in some way.

Who Should Read this Book
This book is designed for researchers and students in a broad variety of
fields: statistics, artificial intelligence, engineering, finance and others. We
expect that the reader will have had at least one elementary course in
statistics, covering basic topics including linear regression.
We have not attempted to write a comprehensive catalog of learning
methods, but rather to describe some of the most important techniques.
Equally notable, we describe the underlying concepts and considerations
by which a researcher can judge a learning method. We have tried to write
this book in an intuitive fashion, emphasizing concepts rather than math-
ematical details.
As statisticians, our exposition will naturally reflect our backgrounds and
areas of expertise. However in the past eight years we have been attending
conferences in neural networks, data mining and machine learning, and our
thinking has been heavily influenced by these exciting fields. This influence
is evident in our current research, and in this book.

How This Book is Organized
Our view is that one must understand simple methods before trying to
grasp more complex ones. Hence, after giving an overview of the supervis-
ing learning problem in Chapter 2, we discuss linear methods for regression
and classification in Chapters 3 and 4. In Chapter 5 we describe splines,
wavelets and regularization/penalization methods for a single predictor,
while Chapter 6 covers kernel methods and local regression. Both of these
sets of methods are important building blocks for high-dimensional learn-
ing techniques. Model assessment and selection is the topic of Chapter 7,
covering the concepts of bias and variance, overfitting and methods such as
cross-validation for choosing models. Chapter 8 discusses model inference
and averaging, including an overview of maximum likelihood, Bayesian in-
ference and the bootstrap, the EM algorithm, Gibbs sampling and bagging,
A related procedure called boosting is the focus of Chapter 10.
In Chapters 9–13 we describe a series of structured methods for su-
pervised learning, with Chapters 9 and 11 covering regression and Chap-
ters 12 and 13 focusing on classification. Chapter 14 describes methods for
unsupervised learning. Two recently proposed techniques, random forests
and ensemble learning, are discussed in Chapters 15 and 16. We describe
undirected graphical models in Chapter 17 and finally we study high-
dimensional problems in Chapter 18.
At the end of each chapter we discuss computational considerations im-
portant for data mining applications, including how the computations scale
with the number of observations and predictors. Each chapter ends with
Bibliographic Notes giving background references for the material.

We recommend that Chapters 1–4 be first read in sequence. Chapter 7
should also be considered mandatory, as it covers central concepts that
pertain to all learning methods. With this in mind, the rest of the book
can be read sequentially, or sampled, depending on the reader’s interest.
indicates a technically difficult section, one that can
The symbol
be skipped without interrupting the flow of the discussion.

Book Website
The website for this book is located at
http://www-stat.stanford.edu/ElemStatLearn
It contains a number of resources, including many of the datasets used in
this book.
Note for Instructors
We have successively used the first edition of this book as the basis for a
two-quarter course, and with the additional materials in this second edition,
it could even be used for a three-quarter sequence. Exercises are provided at
the end of each chapter. It is important for students to have access to good
software tools for these topics. We used the R and S-PLUS programming
languages in our courses.


## 关键词

- statistical learning: 统计学习
- feature: 特征
- training set: 训练集
- learner: 学习模型
- supervised learning
- unsupervised learning
- classification
