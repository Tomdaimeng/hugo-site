+++
title = "ESL-9.6 Missing Data"
summary = """
统计学习基础（译注）第九章第六节，第 332-333 页。
"""

date = 2019-01-02T11:38:00+08:00
lastmod = 2019-01-02T11:38:00+08:00
draft = true
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

It is quite common to have observations with missing values for one or more
input features. The usual approach is to impute (fill-in) the missing values
in some way.

However, the first issue in dealing with the problem is determining wheth-
er the missing data mechanism has distorted the observed data. Roughly
speaking, data are missing at random if the mechanism resulting in its
omission is independent of its (unobserved) value. A more precise definition
is given in Little and Rubin (2002). Suppose y is the response vector and X
is the N × p matrix of inputs (some of which are missing). Denote by X obs
the observed entries in X and let Z = (y, X), Z obs = (y, X obs ). Finally, if R
is an indicator matrix with ijth entry 1 if x ij is missing and zero otherwise,
then the data is said to be missing at random (MAR) if the distribution of
R depends on the data Z only through Z obs :

$$\text{Pr}(\mathbf{R}|\mathbf{Z}, \theta) =
\text{Pr}(\mathbf{R}|\mathbf{Z}\_\text{obs}, \theta) \tag{9.31}$$

Here θ are any parameters in the distribution of R. Data are said to be
missing completely at random (MCAR) if the distribution of R doesn’t
depend on the observed or missing data:

$$\text{Pr}(\mathbf{R}|\mathbf{Z}, \theta) =
\text{Pr}(\mathbf{R}|\theta) \tag{9.32}$$

MCAR is a stronger assumption than MAR: most imputation methods rely
on MCAR for their validity.

For example, if a patient’s measurement was not taken because the doctor
felt he was too sick, that observation would not be MAR or MCAR. In this
case the missing data mechanism causes our observed training data to give a
distorted picture of the true population, and data imputation is dangerous
in this instance. Often the determination of whether features are MCAR
must be made from information about the data collection process. For
categorical features, one way to diagnose this problem is to code “missing”
as an additional class. Then we fit our model to the training data and see
if class “missing” is predictive of the response.

Assuming the features are missing completely at random, there are a
number of ways of proceeding:

1. Discard observations with any missing values.
2. Rely on the learning algorithm to deal with missing values in its
training phase.
3. Impute all missing values before training.

Approach (1) can be used if the relative amount of missing data is small,
but otherwise should be avoided. Regarding (2), CART is one learning
algorithm that deals effectively with missing values, through surrogate splits
(Section 9.2.4). MARS and PRIM use similar approaches. In generalized
additive modeling, all observations missing for a given input feature are
omitted when the partial residuals are smoothed against that feature in
the backfitting algorithm, and their fitted values are set to zero. Since the
fitted curves have mean zero (when the model includes an intercept), this
amounts to assigning the average fitted value to the missing observations.

For most learning methods, the imputation approach (3) is necessary.
The simplest tactic is to impute the missing value with the mean or median
of the nonmissing values for that feature. (Note that the above procedure
for generalized additive models is analogous to this.)

If the features have at least some moderate degree of dependence, one
can do better by estimating a predictive model for each feature given the
other features and then imputing each missing value by its prediction from
the model. In choosing the learning method for imputation of the features,
one must remember that this choice is distinct from the method used for
predicting y from X. Thus a flexible, adaptive method will often be pre-
ferred, even for the eventual purpose of carrying out a linear regression of y
on X. In addition, if there are many missing feature values in the training
set, the learning method must itself be able to deal with missing feature
values. CART therefore is an ideal choice for this imputation “engine.”

After imputation, missing values are typically treated as if they were ac-
tually observed. This ignores the uncertainty due to the imputation, which
will itself introduce additional uncertainty into estimates and predictions
from the response model. One can measure this additional uncertainty by
doing multiple imputations and hence creating many different training sets.
The predictive model for y can be fit to each training set, and the variation
across training sets can be assessed. If CART was used for the imputation
engine, the multiple imputations could be done by sampling from the values
in the corresponding terminal nodes.