+++
title = "ESL-9.7 Computational Considerations"
summary = """
统计学习基础（译注）第九章第七节，第 334 页。
"""

date = 2019-01-02T11:48:00+08:00
lastmod = 2019-01-02T11:48:00+08:00
draft = true
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

With N observations and p predictors, additive model fitting requires some
number mp of applications of a one-dimensional smoother or regression
method. The required number of cycles m of the backfitting algorithm is
usually less than 20 and often less than 10, and depends on the amount
of correlation in the inputs. With cubic smoothing splines, for example,
N log N operations are needed for an initial sort and N operations for the
spline fit. Hence the total operations for an additive model fit is pN log N +
mpN .

Trees require pN log N operations for an initial sort for each predictor,
and typically another pN log N operations for the split computations. If the
splits occurred near the edges of the predictor ranges, this number could
increase to N 2 p.

MARS requires N m 2 + pmN operations to add a basis function to a
model with m terms already present, from a pool of p predictors. Hence to
build an M -term model requires N M 3 + pM 2 N computations, which can
be quite prohibitive if M is a reasonable fraction of N .

Each of the components of an HME are typically inexpensive to fit at
each M-step: N p 2 for the regressions, and N p 2 K 2 for a K-class logistic
regression. The EM algorithm, however, can take a long time to converge,
and so sizable HME models are considered costly to fit.