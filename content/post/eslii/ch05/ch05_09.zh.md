+++
title = "ESL-5.9 小波平滑"
summary = """
统计学习基础（译注）第五章第九节，第 174-181 页。
"""

date = 2018-10-29T14:15:00+08:00
lastmod = 2018-10-29T14:15:00+08:00
draft = true
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

We have seen two different modes of operation with dictionaries of basis
functions. With regression splines, we select a subset of the bases, using
either subject-matter knowledge, or else automatically. The more adaptive
procedures such as MARS (Chapter 9) can capture both smooth and non-
smooth behavior. With smoothing splines, we use a complete basis, but
then shrink the coefficients toward smoothness.

Wavelets typically use a complete orthonormal basis to represent func-
tions, but then shrink and select the coefficients toward a sparse represen-
tation. Just as a smooth function can be represented by a few spline basis
functions, a mostly flat function with a few isolated bumps can be repre-
sented with a few (bumpy) basis functions. Wavelets bases are very popular
in signal processing and compression, since they are able to represent both
smooth and/or locally bumpy functions in an efficient way—a phenomenon
dubbed time and frequency localization. In contrast, the traditional Fourier
basis allows only frequency localization.

Before we give details, let’s look at the Haar wavelets in the left panel
of Figure 5.16 to get an intuitive idea of how wavelet smoothing works.
The vertical axis indicates the scale (frequency) of the wavelets, from low
scale at the bottom to high scale at the top. At each scale the wavelets are
“packed in” side-by-side to completely fill the time axis: we have only shown
a selected subset. Wavelet smoothing fits the coefficients for this basis by
least squares, and then thresholds (discards, filters) the smaller coefficients.
Since there are many basis functions at each scale, it can use bases where
it needs them and discard the ones it does not need, to achieve time and
frequency localization. The Haar wavelets are simple to understand, but not
smooth enough for most purposes. The symmlet wavelets in the right panel
of Figure 5.16 have the same orthonormal properties, but are smoother.

Figure 5.17 displays an NMR (nuclear magnetic resonance) signal, which
appears to be composed of smooth components and isolated spikes, plus
some noise. The wavelet transform, using a symmlet basis, is shown in the
lower left panel. The wavelet coefficients are arranged in rows, from lowest
scale at the bottom, to highest scale at the top. The length of each line
segment indicates the size of the coefficient. The bottom right panel shows
the wavelet coefficients after they have been thresholded. The threshold
procedure, given below in equation (5.69), is the same soft-thresholding
rule that arises in the lasso procedure for linear regression (Section 3.4.2).
Notice that many of the smaller coefficients have been set to zero. The
green curve in the top panel shows the back-transform of the thresholded
coefficients: this is the smoothed version of the original signal. In the next
section we give the details of this process, including the construction of
wavelets and the thresholding rule.

5.9.1 Wavelet Bases and the Wavelet Transform
In this section we give details on the construction and filtering of wavelets.
Wavelet bases are generated by translations and dilations of a single scal-
ing function φ(x) (also known as the father). The red curves in Figure 5.18
are the Haar and symmlet-8 scaling functions. The Haar basis is particu-
larly easy to understand, especially for anyone with experience in analysis
of variance or trees, since it produces a piecewise-constant representation.
Thus if φ(x) = I(x ∈ [0, 1]), then φ 0,k (x) = φ(x−k), k an integer, generates
an orthonormal basis for functions with jumps
at the integers. Call this ref-
√
erence space V 0 . The dilations φ 1,k (x) = 2φ(2x−k) form an orthonormal
basis for a space V 1 ⊃ V 0 of functions piecewise constant on intervals of
length 12 . In fact, more generally we have · · · ⊃ V 1 ⊃ V 0 ⊃ V −1 ⊃ · · · where
each V j is spanned by φ j,k = 2 j/2 φ(2 j x − k).

Now to the definition of wavelets. In analysis of variance, we often rep-
resent a pair of means μ 1 and μ 2 by their grand mean μ = 12 (μ 1 + μ 2 ), and
then a contrast α = 12 (μ 1 − μ 2 ). A simplification occurs if the contrast α is
very small, because then we can set it to zero. In a similar manner we might
represent a function in V j+1 by a component in V j plus the component in
the orthogonal complement W j of V j to V j+1 , written as V j+1 = V j ⊕ W j .
The component in W j represents detail, and we might wish to set some ele-
ments of this component to zero. It is easy to see that the functions ψ(x−k)
generated by the mother wavelet ψ(x) = φ(2x)−φ(2x−1) form an orthonor-
mal basis for W 0 for the Haar family. Likewise ψ j,k = 2 j/2 ψ(2 j x − k) form
a basis for W j .

Now V j+1 = V j ⊕ W j = V j−1 ⊕ W j−1 ⊕ W j , so besides representing a
function by its level-j detail and level-j rough components, the latter can
be broken down to level-(j − 1) detail and rough, and so on. Finally we get
a representation of the form V J = V 0 ⊕ W 0 ⊕ W 1 · · · ⊕ W J−1 . Figure 5.16
on page 175 shows particular wavelets ψ j,k (x).
Notice that since these spaces are orthogonal, all the basis functions are
orthonormal. In fact, if the domain is discrete with N = 2 J (time) points,
this is as far as we can go. There are 2 j basis elements at level j, and
adding up, we have a total of 2 J − 1 elements in the W j , and one in V 0 .
This structured orthonormal basis allows for a multiresolution analysis,
which we illustrate in the next section.

While helpful for understanding the construction above, the Haar basis
is often too coarse for practical purposes. Fortunately, many clever wavelet
bases have been invented. Figures 5.16 and 5.18 include the Daubechies
symmlet-8 basis. This basis has smoother elements than the corresponding
Haar basis, but there is a tradeoff:

* Each wavelet has a support covering 15 consecutive time intervals,
  rather than one for the Haar basis. More generally, the symmlet-p
  family has a support of 2p − 1 consecutive intervals. The wider the
  support, the more time the wavelet has to die to zero, and so it can
  achieve this more smoothly. Note that the effective support seems to
  be much narrower.
* The symmlet-p wavelet ψ(x) has p vanishing moments; that is,
  $$\int \psi(x) x^j dx = 0, j=0,\dots, p-1$$                                                                                     
  One implication is that any order-p polynomial over the N = 2 J times
  points is reproduced exactly in V 0 (Exercise 5.18). In this sense V 0
  is equivalent to the null space of the smoothing-spline penalty. The
  Haar wavelets have one vanishing moment, and V 0 can reproduce any
  constant function.

The symmlet-p scaling functions are one of many families of wavelet
generators. The operations are similar to those for the Haar basis: 

* If √ V 0 is spanned by φ(x −P k), then V 1 ⊃ V 0 is spanned by φ 1,k (x) =
  2φ(2x−k) and φ(x) = k∈Z h(k)φ 1,k (x), for some filter coefficients
  h(k).
* W 0 is spanned by ψ(x) = k∈Z g(k)φ 1,k (x), with filter coefficients
  g(k) = (−1) 1−k h(1 − k)

### 5.9.2 Adaptive Wavelet Filtering :scream:

Wavelets are particularly useful when the data are measured on a uniform
lattice, such as a discretized signal, image, or a time series. We will focus on
the one-dimensional case, and having N = 2 J lattice-points is convenient.
Suppose y is the response vector, and W is the N ×N orthonormal wavelet
basis matrix evaluated at the N uniformly spaced observations. Then y ∗ =
W T y is called the wavelet transform of y (and is the full least squares
regression coefficient). A popular method for adaptive wavelet fitting is
known as SURE shrinkage (Stein Unbiased Risk Estimation, Donoho and
Johnstone (1994)). We start with the criterion

$$\min\_\theta \\|\mathbf{y} - \mathbf{W}\mathbf{\theta}\\|^2\_2+
2\lambda\\|\theta\\|\_1 \tag{5.68}$$

which is the same as the lasso criterion in Chapter 3. Because W is or-
thonormal, this leads to the simple solution:

$$\hat{\theta}\_j = \text{sign}(y\_j^\*)(\|y\_j^\*\|-\lambda)\_+$$

The least squares coefficients are translated toward zero, and truncated
at zero. The fitted function (vector) is then given by the inverse wavelet
transform f̂ = W θ̂.

A simple choice for λ is λ = σ 2 log N , where σ is an estimate of the
standard deviation of the noise. We can give some motivation for this choice.
Since W is an orthonormal transformation, if the elements of y are white
noise (independent Gaussian variates with mean 0 and variance σ 2 ), then
so are y ∗ . Furthermore if random variables Z 1 , Z 2 , . . . , Z N are white
√ noise,
the expected maximum of |Z √ j |, j = 1, . . . , N is approximately σ 2 log N .
Hence all coefficients below σ 2 log N are likely to be noise and are set to
zero.

The space W could be any basis of orthonormal functions: polynomials,
natural splines or cosinusoids. What makes wavelets special is the particular
form of basis functions used, which allows for a representation localized in
time and in frequency.

Let’s look again at the NMR signal of Figure 5.17. The wavelet transform
was computed using a symmlet−8 basis. Notice that the coefficients do not
descend all the way to V 0 , but stop at V 4 which has 16 basis functions.
As we ascend to each level of detail, the coefficients get smaller, except in
locations where spiky behavior is present. The wavelet coefficients represent
characteristics of the signal localized in time (the basis functions at each
level are translations of each other) and localized in frequency. Each dilation
increases the detail by a factor of two, and in this sense corresponds to
doubling the frequency in a traditional Fourier representation. In fact, a
more mathematical understanding of wavelets reveals that the wavelets at
a particular scale have a Fourier transform that is restricted to a limited
range or octave of frequencies.

The shrinking/truncation in the right panel was achieved using the SURE
approach described in the introduction to this section. The orthonormal
N × N basis matrix W has columns which are the wavelet basis functions
evaluated at the N time points. In particular, in this case there will be 16
columns corresponding to the φ 4,k (x), and the remainder devoted to the
ψ j,k (x), j = 4, . . . , 11. In practice λ depends on the noise variance, and has
to be estimated from the data (such as the variance of the coefficients at
the highest level).

Notice the similarity between the SURE criterion (5.68) on page 179,
and the smoothing spline criterion (5.21) on page 156:

* Both are hierarchically structured from coarse to fine detail, although
wavelets are also localized in time within each resolution level.
* The splines build in a bias toward smooth functions by imposing
differential shrinking constants d k . Early versions of SURE shrinkage
treated all scales equally. The S+wavelets function waveshrink() has
many options, some of which allow for differential shrinkage.
* The spline L 2 penalty cause pure shrinkage, while the SURE L 1
penalty does shrinkage and selection.

More generally smoothing splines achieve compression of the original signal
by imposing smoothness, while wavelets impose sparsity. Figure 5.19 com-
pares a wavelet fit (using SURE shrinkage) to a smoothing spline fit (using
cross-validation) on two examples different in nature. For the NMR data in
the upper panel, the smoothing spline introduces detail everywhere in order
to capture the detail in the isolated spikes; the wavelet fit nicely localizes
the spikes. In the lower panel, the true function is smooth, and the noise is
relatively high. The wavelet fit has let in some additional and unnecessary
wiggles—a price it pays in variance for the additional adaptivity.

The wavelet transform is not performed by matrix multiplication as in
y ∗ = W T y. In fact, using clever pyramidal schemes y ∗ can be obtained
in O(N ) computations, which is even faster than the N log(N ) of the fast
Fourier transform (FFT). While the general construction is beyond the
scope of this book, it is easy to see for the Haar basis (Exercise 5.19).
Likewise, the inverse wavelet transform W θ̂ is also O(N ).

This has been a very brief glimpse of this vast and growing field. There is
a very large mathematical and computational base built on wavelets. Mod-
ern image compression is often performed using two-dimensional wavelet
representations.