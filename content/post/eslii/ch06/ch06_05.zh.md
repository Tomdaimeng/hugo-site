+++
title = "ESL-6.5 局部似然和其他模型"
summary = """
统计学习基础（译注）第六章第五节，第 205-208 页。
只要可以对样本加权，任意的参数模型都可以用在局部模型中。
局部拟合可以比较有效地探测到数据中的非线性关系。
"""

date = 2018-11-22T16:40:00+08:00
lastmod = 2019-02-12T16:00:00+08:00
draft = false
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

局部回归和变参数模型的理念的适用范围极大：
只要模型拟合中可对样本加权，则任意参数模型都可以用在局部。
以下为几个例子：

* 每个样本 $y\_i$ 对应着一个参数，其对变量 $x\_i$ 呈线性[^1]，
  即 $\theta\_i = \theta(x\_i) = x\_i^T \beta$；
  而对 $\beta$ 的推断则是基于对数似然函数
  $ l(\beta) = \sum\_{i=1}^N l(y\_i, x\_i^T \beta)$。
  在 $x\_0$ 的局部推断 $\theta(x\_0) = x\_0^T\beta(x\_0)$，
  可以用更灵活的局部似然函数：
  $$l(\beta(x\_0)) = \sum\_{i=1}^N
  K\_\lambda(x\_0, x\_i) l(y\_i, x\_i^T\beta(x\_0))$$
  很多似然模型，特别是包括了对数几率（逻辑）和对数线性模型的广义线性模型，
  都以线性函数的方式引入自变量的作用。
  局部似然可将模型的全局线性假设放松到局部线性。

* 与上述类似，但系数 $\theta$ 所依赖的变量
  与定义了局部似然函数的变量是不同的：
  $$l(\theta(x\_0)) = \sum\_{i=1}^N
  K\_\lambda(x\_0, x\_i) l(y\_i, \eta(x\_i, \theta(x\_0)))$$
  例如，若 $\eta(x, \theta) = x^T\theta$ 为 $x$ 的线性模型，
  则通过最大化局部似然得到的是一个变参数模型。

* $k$阶自回归时间序列模型可写为
  $y\_t = \beta\_0 + \beta\_1 y\_{t-1} + \beta\_2 y\_{t-2} + \cdots +
  \beta\_k y\_{t-k} + \varepsilon\_t$。
  将滞后（lag）变量集合写为
  $z\_t = (y\_{t-1}, y\_{t-2}, \dots, y\_{t-k})$，
  模型类似于一般的线性模型 $y\_t = z\_t^T \beta + \varepsilon\_t$，
  通常用最小二乘来拟合。
  这与根据窗口时间而变化的更传统的动态线性模型是不一样的。

作为局部似然的例子，考虑第四章中多类线性对数几率回归模型（4.36）的局部版本。
样本数据包含特征 $x\_i$ 和与之对应的分类输出变量 $g\_i \in \\{1,2,\dots,J\\}$，
线性模型可写为：

$$\text{Pr}(G=j|X=x) = \frac
{e^{\beta\_{j0} + \beta\_j^T x}}
{1 + \sum\_{k=1}^{J-1} e^{\beta\_{k0} + \beta\_k^T x}}
\tag{6.18}$$

此 J 分类模型的局部对数似然函数可写为：

$$\begin{align}
\sum\_{i=1}^N  & K\_\lambda(x\_0, x\_i)  \Bigg\\{
\beta\_{g\_i 0}(x\_0) + \beta\_{g\_i}(x\_0)^T(x\_i-x\_0) \\\\ & -
\log\bigg[ 1 + \sum\_{k=1}^{J-1}\exp(
  \beta\_{g\_k 0}(x\_0) + \beta\_{g\_k}(x\_0)^T(x\_i-x\_0)
)\bigg]\Bigg\\}\tag{6.19}\end{align}$$

需要注意：

* 上式第一行对应着条件概率中的分子，脚标 $g\_i$ 为第 i 个样本的输出分类。
* 根据多分类模型的定义，$\beta\_{J0}=0$，$\beta\_{J} = 0$。
* 局部回归中的变量对 $x\_0$ 进行了中心化，所以在 $x\_0$ 的拟合后验概率为：
  $$\hat{\text{Pr}}(G=j|X=x\_0) = \frac
  {e^{\hat{\beta}\_{j0}(x\_0)}}
  {1 + \sum\_{k=1}^{J-1} e^{\hat{\beta}\_{k0}(x\_0)}}
  \tag{6.20}$$

这个模型可用在适当低维度的灵活多分类问题中，
但在高维的邮政编码分类问题中的表现也很好。
使用核函数平滑方法的广义加性模型（第九章）与此联系紧密，
通过对回归函数的加性结构假设来规避维数问题。

{{< figure
  src="http://public.guansong.wang/eslii/ch06/eslii_fig_06_12.png"
  title="**图6.12**：每个图都为南非心脏病数据样本中二分类输出变量 CHD（冠心病）作为一个风险因子的函数曲线。每个图中的曲线为使用局部线性对数几率回归模型的患病率拟合结果。在曲线左侧意外地出现了患病率的提升，是因为数据样本的回溯性，即一些患病者已进行了降低血压和体重的治疗。图中阴影区域为逐点估计的标准误差带。"
>}}

作为一个简单的演示，
下面对第四章中的心脏病数据拟合一个二分类的局部线性对数几率模型。
图 6.12 展示了两个风险因子（各自的）单变量局部对数几率模型拟合。
在数据样本本身的可视化无法提供太多信息时，
这种图形对探测非线性关系很有帮助。
在此例中可见数据一个出乎意料的异常[^3]，
若用传统的方法可能不会被发现。

由于 CHD 为二分类的指示变量，
其实可以不通过似然变换，
直接简单地对这个二元输出变量进行平滑来估计条件患病率。
这相当与拟合一个局部常数的对数几率回归模型（练习 6.5）。
为了获得局部线性平滑的偏差修正能力，
通常会在无限制的对数几率尺度（logit scale）上进行这样的计算。

在对数几率回归中，在计算参数估计时通常也会计算它们的标注误差。
如图中所见，这也可以在局部完成，逐点地计算拟合值的标准误差范围。

[^1]: 可以理解为一个广义加性模型：$Y=g(\theta) = g(X^T\beta)$。
[^3]: 异常所指的大概是右图中血压和肥胖低的区域反而出现了心脏病概率的增加，即一个非线性的关系。