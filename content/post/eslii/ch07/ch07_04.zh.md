+++
title = "ESL-7.4 训练误差率中的乐观值"
summary = """
统计学习基础（译注）第七章第四节，第 228-230 页。
更详细地描述了衡量模型的几种不同的“误差”。
训练误差会低估泛化误差，其差距被定义为“乐观值”。
其原因不止是样本外与样本内的差别，
即使在样本内，乐观值也会随着模型的拟合程度而变化。
"""

date = 2018-11-29T22:50:00+08:00
lastmod = 2018-11-29T22:50:00+08:00
draft = false
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

对误差率的估计中需要明确哪些变量是固定的哪些是随机的，
所以在讨论中可能引起困惑[^1]。
在此我们会引入几个概念，详细阐释一下
[第 7.2 节](({{< ref "/post/eslii/ch07/ch07_02.zh.md" >}}))
中的内容。
给定训练集
$\mathcal{T} = \\{(x\_i, y\_i)\\}\_{i=1}^N$，
模型 $\hat{f}$ 的泛化误差为：

$$\text{Err}\_\mathcal{T} =
E\_{X^0, Y^0}[L(Y^0, \hat{f}(X^0))|\mathcal{T}]]
\tag{7.15}$$

注意在等式 7.15 中训练集 $\mathcal{T}$ 是固定的。
$(X^0, Y^0)$ 为从总体联合分布 $F$ 随机生成的新测试样本点。
再对训练集 $\mathcal{T}$ 取平均，则得到预期误差：

$$\text{Err} =
E\_{\mathcal{T}}E\_{X^0, Y^0}[L(Y^0, \hat{f}(X^0))|\mathcal{T}]]
\tag{7.16}$$

预期误差更易于进行统计分析。
上文中曾提过，大多数方法对预期误差的估计要好于对
$\text{Err}\mathcal{T}$ 的估计[^2]。
第 7.12 节对此有更多说明。

训练误差为：

$$\overline{\text{err}} =
\frac{1}{N}\sum\_{i=1}^N L(y\_i, \hat{f}(x\_i))
\tag{7.17}$$

由于这个误差的评估与模型拟合使用相同的数据，
其通常要小于真实的误差 $\text{Err}\_\mathcal{T}$（练习 2.9）。
模型的拟合通常对训练样本有一定的适应性，
因此训练误差或表现（apparent）误差 $\overline{\text{err}}$
是对泛化误差 $\text{Err}\_\mathcal{T}$ 的估计过于乐观。

评估点的选取位置也是造成两者之间差异的一部分原因。
由于测试的输入向量可以与训练样本中的向量都不相同，
可认为 $\text{Err}\_{\mathcal{T}}$ 代表了样本外（extra-sample）的误差。
为了更易于理解 $\overline{\text{err}}$ 的“乐观”性，
考虑样本内（in-sample）误差：

$$\text{Err}\_{\text{in}} = \frac{1}{N}
\sum_{i=1}^N E\_{Y^0} [L(Y^0\_i, \hat{f}(x\_i))|\mathcal{T}]
\tag{7.18}$$

式中的 $Y^0$ 表示了这些是在训练样本的每个输入向量点
$x\_i$，$i=1,2,\dots,N$ 处采集的 $N$ 个新输出变量取值。
将**乐观值**（optimism）量化定义为
$\text{Err}\_\{\text{in}}$ 与训练误差 $\overline{err}$ 之间的差：

$$\text{op} \equiv \text{Err}\_{\text{in}} - \overline{\text{err}}
\tag{7.19}$$

$\overline{\text{err}}$ 通常是对预测误差的低估，
因此上式通常大于零。
最后，平均乐观值是在（固定）训练集位置上的期望:

$$w \equiv E\_\mathcal{y} \text{op} \tag{7.20}$$

这里固定了训练集的自变量取值，
对训练集的输出变量取值取期望。
因此期望的下标为 $E\_\mathbf{y}$ 而不是 $E\_\mathcal{T}$。
类似于我们可以估计预期误差 $\text{Err}$
却无法估计条件误差 $\text{Err}\_\mathcal{T}$，
我们通常只能估计预期误差 $w$ 而无法估计 $\text{op}$。

对平方误差、0-1和其他损失函数，可证明一个一般性的结论：

$$w = \frac{2}{N}\sum\_{i=1}^N \text{Cov}(\hat{y}\_i, y\_i)\tag{7.21}$$

其中 Cov 为协方差。
因此 $\overline{\text{err}}$ 对真实误差低估的程度
取决于 $y\_i$ 对它本身的预测结果的影响有多大。
对样本的拟合越彻底，$\text{Cov}(\hat{y}\_i, y\_i)$ 就越大，
因此乐观值就会增大。
练习 7.4 在回归拟合值 $\hat{y}\_i$
和使用平方误差损失的问题中证明了这个结论。
对于 0-1 损失，
$\hat{y}\_i \in \\{0,1\\}$ 是对 $x\_i$ 的分类；
对于熵损失，
$\hat{y}\_i \in [0,1]$ 是 $x\_i$ 的分类为类型 1 的概率拟合值。

总之，我们得到了一个重要的等式：

$$E\_\mathbf{y}(\text{Err}\_\text{in}) =
E\_\mathbf{y}(\overline{\text{err}}) +
\frac{2}{N}\sum\_{i=1}^N \text{Cov}(\hat{y}\_i, y\_i)
\tag{7.22}$$

若 $\hat{y}\_i$ 来自于 $d$ 个输入变量或基函数的线性拟合，
则可将上式简化。
例如对于加性误差的模型 $Y=f(X)+\varepsilon$：

$$\sum\_{i=1}^N \text{Cov}(\hat{y}\_i, y\_i) = d\sigma^2\_\varepsilon
\tag{7.23}$$

代入后：

$$E\_\mathbf{y}(\text{Err}\_\text{in}) =
E\_\mathbf{y}(\overline{\text{err}}) +
2\cdot\frac{d}{N}\sigma^2\_\varepsilon
\tag{7.24}$$

表达式 7.23 是第 7.6 节要讨论的**有效参数个数**定义的基础。
乐观值随着模型中使用的输入变量或基函数个数线性增长，
但随着训练样本量的增加而降低。
表达式 7.24 对其他误差模型也大致成立，
比如二分类数据以及熵损失。

一个显而易见的预测误差估计方法是先得出乐观值的估计，
然后再将其与训练误差 $\overline{\text{err}}$ 相加。
下一节会介绍在对参数为线性的模型族中，
一些诸如 $C\_p$、AIC、BIC的方法就是采取这种策略。

与之相比，本章稍后的交叉验证和自助抽样法直接估计样本外误差 $\text{Err}$。
这种通用的工具可以适用于任何损失函数，以及非线性和自适应的拟合方法上。

未来要进行预测的特征不太可能在训练样本中存在一样的取值，
我们通常不直接关心样本内误差。
但样本内误差在模型对比中比较方便而且通常会得到有效的模型选择。
这是因为在对比中重要的是误差的相对的大小关系（而不是绝对的取值大小）。

[^1]: 原文脚注1：实际上在本书的第一版中，本节的讨论就不够清楚。
[^2]: 原文为 $E\_\mathcal{T}$，译者认为是笔误。