+++
title = "ESL-7.2 偏差、方差和模型复杂度"
summary = """
统计学习基础（译注）第七章第二节，第 219-223 页。
本节介绍模型选择和评估的一般性概念。
在理想情况下，一般将数据分为训练集、验证集和测试集，
分别用来拟合模型、选择模型和评估最终模型。
其中选择模型和评估模型都基于模型的测试误差，而不是训练误差。
"""

date = 2018-11-27T17:38:00+08:00
lastmod = 2018-11-27T17:38:00+08:00
draft = false
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

图 7.1 说明了评估学习方法泛化能力的重要性。
先考虑一个数值或区间尺度的输出变量。
目标变量为 $Y$，输入向量为 $X$，
$\hat{f}(X)$ 是从训练集 $\mathcal{T}$ 估计得到的预测模型 。
衡量 $Y$ 与 $\hat{f}(X)$ 之间偏差的损失函数记为
$L(Y, \hat{f}(X))$，
常见的选择有：

$$L(Y, \hat{f}(X)) =\begin{cases}
(Y - \hat{f}(X))^2 & \text{ 平方误差} \\\\  \|Y-\hat{f}(X)\| & \text{ 绝对误差}
\end{cases}\tag{7.1}$$

**测试误差**（test error），也称为**泛化误差**（generlization error），
为在一个独立的测试样本上的预测误差：

$$\text{Err}\_{\mathcal{T}} =
E[L(Y, \hat{f}(X)) | \mathcal{T}]\tag{7.2}$$

其中 $X$ 和 $Y$ 的期望是对它们的（总体）联合分布计算的。
这里的训练集 $\mathcal{T}$ 是固定的，
测试误差指的是这个特定训练集的误差。
另一个相关的指标是期望预测误差（或期望测试误差）：

$$\text{Err} = E[L(Y, \hat{f}(X))] = E[\text{Err}\_{\mathcal{T}}]
\tag{7.3}$$

注意在上式中的期望是对所有随机成分的平均，
包括生成 $\hat{f}$ 的训练集的随机性。

{{< figure
  src="http://public.guansong.wang/eslii/ch07/eslii_fig_07_01.png"
  title="**图7.1**：测试集和训练集误差随模型复杂度变化的表现。浅蓝色曲线为训练误差 $\bar{\text{err}}$；浅红色曲线为 100 组大小为 50 的训练集产生模型的条件测试误差 $\text{Err}\_\mathcal{T}$，横轴为模型复杂度。深色曲线分别对应着期望训练误差 $E[\bar{\text{err}}]$ 和期望测试误差 $\text{Err}$。"
>}}

图 7.1 中展示了 100 组大小为 50 的模拟训练集的预测误差
$\text{Err}\_\mathcal{T}$（浅红色曲线）。
预测误差对模型复杂度的曲线来自套索（lasso）拟合
（[第 3.4.2 节](({{< ref "/post/eslii/ch03/ch03_04.zh.md" >}}))）。
深红色曲线为它们的平均，因此是对 $\text{Err}$ 的估计。

通常的目标是估计 $\text{Err}\_\mathcal{T}$，
但 $\text{Err}$ 更易于进行统计分析，
并且大多数方法都是对预期误差的有效估计。
在只有一个训练样本提供的信息下，
反而不太可能有效地估计出条件误差。
第 7.12 节会对此提供更多讨论。

**训练误差**（training error）为在训练样本上的平均误差：

$$\overline{\text{err}} =
\frac{1}{N} \sum\_{i=1}^N L(y\_i, \hat{f}(x\_i))\tag{7.4}$$

我们想要的是估计模型 $\hat{f}$ 的预期测试误差。
模型越复杂，对训练集的使用越彻底，同时会适应数据中更复杂的潜在关系。
所以，这是一个偏差降低而方差升高的过程。
这其中会有一个复杂度适中的模型可以达到最小的期望测试误差。

但如图 7.1 所示，
训练误差并不是对测试误差的一个好的估计。
训练误差随着模型复杂度增大而一致地降低，
如果将复杂度增加到一定程度，通常会达到零误差。
不过零训练误差的模型是对训练集的过拟合，
通常泛化表现会很差。

对定性或分类输出变量也有一样的结论，
假设 $G$ 取值为集合 $\mathcal{G}$ 中 $K$ 个元素之一，
方便期间标记为 $1, 2, \dots, K$。
通常会对概率
$p\_k(X) = \text{Pr}(G=k|X)$
（或其某个单调变换 $f\_k(X)$）建模，
再得到分类结果 $\hat{G}(X) = \text{argmax}\_k \hat{p}\_k(X)$。
在某些案例中，比如 1-近邻分类（第二和十三章），
也会直接生成 $\hat{G}(X)$。
损失函数通常为：

$$\begin{align}
L(G, \hat{G}(X)) &=
\underbrace{I(G \ne \hat{G}(X))}\_\text{0-1 loss}
\tag{7.5} \\\\ L(G, \hat{p}(X)) &=
-2 \sum\_{k=1}^K I(G=k) \log \hat{p}\_k(X) \\\\ &=
\underbrace{-2 \log \hat{p}\_G(X)}\_{-2 \times \text{log-likelihood}}
\tag{7.6}\end{align}$$

$-2$乘对数似然度的数值有时被称为**偏差**（deviance）。

这里的测试误差同样为
$\text{Err}\_\mathcal{T} = E[L(G, \hat{G}(X))|\mathcal{T}]$，
即用样本 $\mathcal{T}$ 训练出的分类器的总体误分类误差；
同时 $\text{Err}$ 则是期望误分类误差。

训练误差是在训练集上类似的定义，例如使用样本对数似然度的模型训练误差为：

$$\overline{\text{err}} = -\frac{2}{N}
\sum\_{i=1}^N \log\hat{p}\_{g\_i}(x\_i) \tag{7.7}$$

对数似然度可作为所有输出变量概率密度的损失函数，
比如泊松、伽玛、指数、对数正态以及其他分布。
若 $Y$ 的概率密度 $\text{Pr}\_{\theta(X)}(Y)$ 的参数 $\theta(X)$
依赖于自变量 $X$，那么：

$$L(Y, \theta(X)) = -2 \cdot \log \text{Pr}\_{\theta(X)}(Y) \tag{7.8}$$

定义式中的“-2”使高斯分布的对数似然度损失恰好等于平方误差损失。

由于本章主要集中在量化输出变量（平方误差损失函数）的场景，
为了便于阐述，本章后续会用 $Y$ 和 $f(X)$ 进行讨论。
其他场景通过一些简单的恰当转换后即可适用。

本章会介绍估计一个模型的期望测试误差的不同方法。
模型通常会有一个或多个调节参数 $\alpha$，
因此和将预测写为 $\hat{f}\_\alpha(x)$。
调节参数控制着模型的复杂度，
我们想要寻找最小化误差的 $\alpha$ 取值，
即在图 7.1 对应着平均测试误差曲线最低点的取值。
即使如此，通常为了书写简便不会强调 $\hat{f}(x)$ 对 $\alpha$ 的依赖。

需要引起注意的是这里有两个不同的目标：

* 模型选择：估计不同模型的表现，来选择最佳模型。
* 模型评估：选定了最终模型，估计其在新数据上的预测误差（泛化误差）。

如果数据量足够大，上述两个问题的最佳解决方法是将样本随机分成三部分：
训练集、验证集和测试集。
训练集用来拟合模型；
验证集用来估计预测误差，选择模型；
测试集用来评估最终选定模型的泛化误差。
最好将测试集保存在“保险柜”中，只在模型分析的最后才被取出来。
如果在之前的分析中使用了测试集，比如根据测试集上的误差选择模型，
那么最终选定模型的测试集误差会低估真实的测试误差，
有时程度会很大。

很难给出如何选择三个数据集的样本量的普适规则，
因为这通常取决于数据中的信号噪声比以及样本量的大小。
一个典型的划分方法为
训练集 50%，验证集和测试集各 25%。

{{< figure
  src="http://public.guansong.wang/eslii/ch07/eslii_fig_07_a.png"
>}}

本章中的方法适用于数据量不足以支撑划分为三部分的场景中。
需要再一次说明，很难给出足够的样本量大小的一般性规则；
这取决于潜在回归函数的信号噪声比，待拟合模型的复杂度，以及其他相关设置。

本章中的方法通过分析的方法（AIC，BIC，MDL，SRM）
或对样本有效地再利用（交叉验证和自助抽样）来近似上述的模型验证步骤。
除了用于模型选择外，
这些方法同时也在某种程度上提供了最终选定模型测试误差的一个可信的估计。

在介绍这些方法之前，下一节会先详细地探究测试误差的性质，
以及偏差-方差权衡。