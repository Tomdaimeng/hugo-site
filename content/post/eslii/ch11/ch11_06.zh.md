+++
title = "ESL-11.6 Example: Simulated Data"
summary = """
统计学习基础（译注）第十一章第六节，第 401-404 页。
"""

date = 2019-02-17T20:41:00+08:00
lastmod = 2019-02-17T20:41:00+08:00
draft = true
math = true

authors = ["Butters"]
tags = ["译文"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

We generated data from two additive error models Y = f (X) + ε:

$$\begin{align}
\text{Sum of sigmoids:} & &
Y = \sigma(a\_1^T X) + \sigma(a\_2^T X) + \varepsilon\_1
\\\\ \text{Radial:} & &
Y = \prod\_{m=1}^{10} \phi(X\_m) + \varepsilon\_2
\end{align}$$

Here X T = (X 1 , X 2 , . . . , X p ), each X j being a standard Gaussian variate,
with p = 2 in the first model, and p = 10 in the second.

For the sigmoid model, a 1 = (3, 3), a 2 = (3, −3); for the radial model,
φ(t) = (1/2π) 1/2 exp(−t 2 /2). Both ε 1 and ε 2 are Gaussian errors, with
variance chosen so that the signal-to-noise ratio

$$\frac{\text{Var}(E(Y|X))}{\text{Var}(Y-E(Y|X))} =
\frac{\text{Var}(f(X))}{\text{Var}(\varepsilon)} \tag{11.18}$$

is 4 in both models. We took a training sample of size 100 and a test sample
of size 10, 000. We fit neural networks with weight decay and various num-
bers of hidden units, and recorded the average test error E Test (Y − f ˆ (X)) 2
for each of 10 random starting weights. Only one training set was gen-
erated, but the results are typical for an “average” training set. The test
errors are shown in Figure 11.6. Note that the zero hidden unit model refers
to linear least squares regression. The neural network is perfectly suited to
the sum of sigmoids model, and the two-unit model does perform the best,
achieving an error close to the Bayes rate. (Recall that the Bayes rate for
regression with squared error is the error variance; in the figures, we report
test error relative to the Bayes error). Notice, however, that with more hid-
den units, overfitting quickly creeps in, and with some starting weights the
model does worse than the linear model (zero hidden unit) model. Even
with two hidden units, two of the ten starting weight configurations pro-
duced results no better than the linear model, confirming the importance
of multiple starting values.

{{< figure
  src="http://public.guansong.wang/eslii/ch11/eslii_fig_11_06.png"
  title="**图11.6**："
>}}
Boxplots of test error, for simulated data example, relative to
the Bayes error (broken horizontal line). True function is a sum of two sigmoids
on the left, and a radial function is on the right. The test error is displayed for
10 different starting weights, for a single hidden layer neural network with the
number of units as indicated.

A radial function is in a sense the most difficult for the neural net, as it is
spherically symmetric and with no preferred directions. We see in the right
panel of Figure 11.6 that it does poorly in this case, with the test error
staying well above the Bayes error (note the different vertical scale from
the left panel). In fact, since a constant fit (such as the sample average)
achieves a relative error of 5 (when the SNR is 4), we see that the neural
networks perform increasingly worse than the mean.

In this example we used a fixed weight decay parameter of 0.0005, rep-
resenting a mild amount of regularization. The results in the left panel of
Figure 11.6 suggest that more regularization is needed with greater num-
bers of hidden units.

{{< figure
  src="http://public.guansong.wang/eslii/ch11/eslii_fig_11_07.png"
  title="**图11.7**："
>}}
Boxplots of test error, for simulated data example, relative to the
Bayes error. True function is a sum of two sigmoids. The test error is displayed
for ten different starting weights, for a single hidden layer neural network with
the number units as indicated. The two panels represent no weight decay (left)
and strong weight decay λ = 0.1 (right).

In Figure 11.7 we repeated the experiment for the sum of sigmoids model,
with no weight decay in the left panel, and stronger weight decay (λ = 0.1)
in the right panel. With no weight decay, overfitting becomes even more
severe for larger numbers of hidden units. The weight decay value λ = 0.1
produces good results for all numbers of hidden units, and there does not
appear to be overfitting as the number of units increase. Finally, Figure 11.8
shows the test error for a ten hidden unit network, varying the weight decay
parameter over a wide range. The value 0.1 is approximately optimal.

{{< figure
  src="http://public.guansong.wang/eslii/ch11/eslii_fig_11_08.png"
  title="**图11.8**："
>}}
Boxplots of test error, for simulated data example. True function
is a sum of two sigmoids. The test error is displayed for ten different starting
weights, for a single hidden layer neural network with ten hidden units and weight
decay parameter value as indicated.

In summary, there are two free parameters to select: the weight decay λ
and number of hidden units M . As a learning strategy, one could fix either
parameter at the value corresponding to the least constrained model, to
ensure that the model is rich enough, and use cross-validation to choose
the other parameter. Here the least constrained values are zero weight decay
and ten hidden units. Comparing the left panel of Figure 11.7 to Figure
11.8, we see that the test error is less sensitive to the value of the weight
decay parameter, and hence cross-validation of this parameter would be
preferred.