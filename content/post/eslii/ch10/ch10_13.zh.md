+++
title = "ESL-10.13 Interpretation"
summary = """
统计学习基础（译注）第十章第十三节，第 367-370 页。
"""

date = 2019-01-28T15:20:00+08:00
lastmod = 2019-01-28T15:20:00+08:00
draft = true 
math = true

authors = ["Butters"]
tags = []
categories = []

[header]
image = ""
caption = ""
preview = true
+++

Single decision trees are highly interpretable. The entire model can be com-
pletely represented by a simple two-dimensional graphic (binary tree) that
is easily visualized. Linear combinations of trees (10.28) lose this important
feature, and must therefore be interpreted in a different way.

### 10.13.1 Relative Importance of Predictor Variables

In data mining applications the input predictor variables are seldom equally
relevant. Often only a few of them have substantial influence on the re-
sponse; the vast majority are irrelevant and could just as well have not
been included. It is often useful to learn the relative importance or contri-
bution of each input variable in predicting the response.

For a single decision tree T , Breiman et al. (1984) proposed

$$\mathcal{I}\_\ell^2(T) = \sum\_{t=1}^{J-1}
\hat{\imath}^2 I(v(t) = \ell) \tag{10.42}$$

as a measure of relevance for each predictor variable X l . The sum is over
the J − 1 internal nodes of the tree. At each such node t, one of the input
variables X v(t) is used to partition the region associated with that node into
two subregions; within each a separate constant is fit to the response values.
The particular variable chosen is the one that gives maximal estimated
improvement ı̂ 2 t in squared error risk over that for a constant fit over the
entire region. The squared relative importance of variable X l is the sum of
such squared improvements over all internal nodes for which it was chosen
as the splitting variable.

This importance measure is easily generalized to additive tree expansions
(10.28); it is simply averaged over the trees

$$\mathcal{I}\_\ell^2 = \frac{1}{M} \sum\_{m=1}^{M}
\mathcal{I}\_\ell^2(T\_m) \tag{10.43}$$

Due to the stabilizing effect of averaging, this measure turns out to be more
reliable than is its counterpart (10.42) for a single tree. Also, because of
shrinkage (Section 10.12.1) the masking of important variables by others
with which they are highly correlated is much less of a problem. Note
that (10.42) and (10.43) refer to squared relevance; the actual relevances
are their respective square roots. Since these measures are relative, it is
customary to assign the largest a value of 100 and then scale the others
accordingly. Figure 10.6 shows the relevant importance of the 57 inputs in
predicting spam versus email .

For K-class classification, K separate models f k (x), k = 1, 2, . . . , K are
induced, each consisting of a sum of trees

$$f\_k(x) = \sum\_{m=1}^M T\_{km}(x) \tag{10.44}$$

In this case (10.43) generalizes to

$$\mathcal{I}\_{\ell k}^2 = \frac{1}{M} \sum\_{m=1}^M
\mathcal{I}\_\ell^2(T\_{km}) \tag{10.45}$$

Here I lk is the relevance of X l in separating the class k observations from
the other classes. The overall relevance of X l is obtained by averaging over
all of the classes

$$\mathcal{I}\_\ell^2 =  \frac{1}{K} \sum\_{k=1}^K
\mathcal{I}\_{\ell k}^2 \tag{10.46}$$

Figures 10.23 and 10.24 illustrate the use of these averaged and separate
relative importances.

### 10.13.2 Partial Dependence Plots

After the most relevant variables have been identified, the next step is to
attempt to understand the nature of the dependence of the approximation
f (X) on their joint values. Graphical renderings of the f (X) as a function
of its arguments provides a comprehensive summary of its dependence on
the joint values of the input variables.

Unfortunately, such visualization is limited to low-dimensional views.
We can easily display functions of one or two arguments, either continuous
or discrete (or mixed), in a variety of different ways; this book is filled
with such displays. Functions of slightly higher dimensions can be plotted
by conditioning on particular sets of values of all but one or two of the
arguments, producing a trellis of plots (Becker et al., 1996). 1

For more than two or three variables, viewing functions of the corre-
sponding higher-dimensional arguments is more difficult. A useful alterna-
tive can sometimes be to view a collection of plots, each one of which shows
the partial dependence of the approximation f (X) on a selected small sub-
set of the input variables. Although such a collection can seldom provide a
comprehensive depiction of the approximation, it can often produce helpful
clues, especially when f (x) is dominated by low-order interactions (10.40).

Consider the subvector X S of l < p of the input predictor variables X T =
(X 1 , X 2 , . . . , X p ), indexed by S ⊂ {1, 2, . . . , p}. Let C be the complement
set, with S ∪ C = {1, 2, . . . , p}. A general function f (X) will in principle
depend on all of the input variables: f (X) = f (X S , X C ). One way to define
the average or partial dependence of f (X) on X S is

$$f\_\mathcal{S}(X\_\mathcal{S}) = E\_{X\_\mathcal{C}}
f(X\_\mathcal{S}, X\_\mathcal{C}) \tag{10.47}$$

This is a marginal average of f , and can serve as a useful description of the
effect of the chosen subset on f (X) when, for example, the variables in X S
do not have strong interactions with those in X C .

Partial dependence functions can be used to interpret the results of any
“black box” learning method. They can be estimated by

$$\bar{f}\_\mathcal{S}(X\_\mathcal{S}) = \frac{1}{N} \sum\_{i=1}^N
f(X\_\mathcal{S}, x\_{i\mathcal{C}}) \tag{10.48}$$

where {x 1C , x 2C , . . . , x N C } are the values of X C occurring in the training
data. This requires a pass over the data for each set of joint values of X S for
which f  ̄ S (X S ) is to be evaluated. This can be computationally intensive,
even for moderately sized data sets. Fortunately with decision trees, f  ̄ S (X S )
(10.48) can be rapidly computed from the tree itself without reference to
the data (Exercise 10.11).

It is important to note that partial dependence functions defined in
(10.47) represent the effect of X S on f (X) after accounting for the (av-
erage) effects of the other variables X C on f (X). They are not the effect
of X S on f (X) ignoring the effects of X C . The latter is given by the con-
ditional expectation

$$\tilde{f}\_\mathcal{S}(X\_\mathcal{S}) =
E(f(X\_\mathcal{S}, X\_\mathcal{C}) | X\_\mathcal{S}) \tag{10.49}$$

and is the best least squares approximation to f (X) by a function of X S
alone. The quantities f  ̃ S (X S ) and f  ̄ S (X S ) will be the same only in the
unlikely event that X S and X C are independent. For example, if the effect
of the chosen variable subset happens to be purely additive,

$$f(X) = h\_1(X\_\mathcal{S}) + h\_2(X\_\mathcal{C}) \tag{10.50}$$

Then (10.47) produces the h 1 (X S ) up to an additive constant. If the effect
is purely multiplicative,

$$f(X) = h\_1(X\_\mathcal{S}) \cdot h\_2(X\_\mathcal{C}) \tag{10.51}$$

then (10.47) produces h 1 (X S ) up to a multiplicative constant factor. On
the other hand, (10.49) will not produce h 1 (X S ) in either case. In fact,
(10.49) can produce strong effects on variable subsets for which f (X) has
no dependence at all.

Viewing plots of the partial dependence of the boosted-tree approxima-
tion (10.28) on selected variables subsets can help to provide a qualitative
description of its properties. Illustrations are shown in Sections 10.8 and
10.14. Owing to the limitations of computer graphics, and human percep-
tion, the size of the subsets X S must be small (l ≈ 1, 2, 3). There are of
course a large number of such subsets, but only those chosen from among
the usually much smaller set of highly relevant predictors are likely to be
informative. Also, those subsets whose effect on f (X) is approximately
additive (10.50) or multiplicative (10.51) will be most revealing.

For K-class classification, there are K separate models (10.44), one for
each class. Each one is related to the respective probabilities (10.21) through

$$f\_k(X) = \log p\_k(X) - \frac{1}{K} \sum\_{l=1}^K \log p\_l(X)
\tag{10.52}$$

Thus each f k (X) is a monotone increasing function of its respective prob-
ability on a logarithmic scale. Partial dependence plots of each respective
f k (X) (10.44) on its most relevant predictors (10.45) can help reveal how
the log-odds of realizing that class depend on the respective input variables.

[^1]: lattice in R.