+++
title = "ESL-10.8 Example: Spam Data"
summary = """
统计学习基础（译注）第十章第八节，第 352-353 页。
"""

date = 2019-01-24T16:33:00+08:00
lastmod = 2019-01-24T16:33:00+08:00
draft = true 
math = true

authors = ["Butters"]
tags = []
categories = []

[header]
image = ""
caption = ""
preview = true
+++

Before we go into the details of gradient boosting, we demonstrate its abili-
ties on a two-class classification problem. The spam data are introduced in
Chapter 1, and used as an example for many of the procedures in Chapter 9
(Sections 9.1.2, 9.2.5, 9.3.1 and 9.4.1).

Applying gradient boosting to these data resulted in a test error rate of
4.5%, using the same test set as was used in Section 9.1.2. By comparison,
an additive logistic regression achieved 5.5%, a CART tree fully grown and
pruned by cross-validation 8.7%, and MARS 5.5%. The standard error of
these estimates is around 0.6%, although gradient boosting is significantly
better than all of them using the McNemar test (Exercise 10.6).

In Section 10.13 below we develop a relative importance measure for
each predictor, as well as a partial dependence plot describing a predictor’s
contribution to the fitted model. We now illustrate these for the spam data.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_06.png"
  title="**图10.6**："
>}}
Predictor variable importance spectrum for the spam data. The
variable names are written on the vertical axis.

Figure 10.6 displays the relative importance spectrum for all 57 predictor
variables. Clearly some predictors are more important than others in sep-
arating spam from email . The frequencies of the character strings ! , $ , hp ,
and remove are estimated to be the four most relevant predictor variables.
At the other end of the spectrum, the character strings 857 , 415 , table , and
3d have virtually no relevance.

The quantity being modeled here is the log-odds of spam versus email

$$f(x) = \log
\frac{\text{Pr}(\text{spam}|x)}{\text{Pr}(\text{email}|x)} \tag{10.24}$$

(see Section 10.13 below).Figure 10.7 shows the partial dependence of the
log-odds on selected important predictors, two positively associated with
spam ( ! and remove ), and two negatively associated ( edu and hp ). These
particular dependencies are seen to be essentially monotonic. There is a
general agreement with the corresponding functions found by the additive
logistic regression model; see Figure 9.1 on page 303.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_07.png"
  title="**图10.7**："
>}}
Partial dependence of log-odds of spam on four important pre-
dictors. The red ticks at the base of the plots are deciles of the input variable.

Running a gradient boosted model on these data with J = 2 terminal-
node trees produces a purely additive (main effects) model for the log-
odds, with a corresponding error rate of 4.7%, as compared to 4.5% for the
full gradient boosted model (with J = 5 terminal-node trees). Although
not significant, this slightly higher error rate suggests that there may be
interactions among some of the important predictor variables. This can
be diagnosed through two-variable partial dependence plots. Figure 10.8
shows one of the several such plots displaying strong interaction effects.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_08.png"
  title="**图10.8**："
>}}
Partial dependence of the log-odds of spam vs. email as a func-
tion of joint frequencies of hp and the character !.

One sees that for very low frequencies of hp , the log-odds of spam are
greatly increased. For high frequencies of hp , the log-odds of spam tend to
be much lower and roughly constant as a function of ! . As the frequency
of hp decreases, the functional relationship with ! strengthens.