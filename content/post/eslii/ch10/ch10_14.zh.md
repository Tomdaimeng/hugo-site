+++
title = "ESL-10.14 Illustrations"
summary = """
统计学习基础（译注）第十章第十四节，第 371-383 页。
"""

date = 2019-01-28T15:30:00+08:00
lastmod = 2019-01-28T15:30:00+08:00
draft = true 
math = true

authors = ["Butters"]
tags = []
categories = []

[header]
image = ""
caption = ""
preview = true
+++

In this section we illustrate gradient boosting on a number of larger datasets,
using different loss functions as appropriate.

### 10.14.1 California Housing

This data set (Pace and Barry, 1997) is available from the Carnegie-Mellon
StatLib repository 2 . It consists of aggregated data from each of 20,460
neighborhoods (1990 census block groups) in California. The response vari-
able Y is the median house value in each neighborhood measured in units of
$100,000. The predictor variables are demographics such as median income
MedInc , housing density as reflected by the number of houses House , and the
average occupancy in each house AveOccup . Also included as predictors are
the location of each neighborhood ( longitude and latitude ), and several
quantities reflecting the properties of the houses in the neighborhood: av-
erage number of rooms AveRooms and bedrooms AveBedrms . There are thus
a total of eight predictors, all numeric.

We fit a gradient boosting model using the MART procedure, with J = 6
terminal nodes, a learning rate (10.41) of ν = 0.1, and the Huber loss
criterion for predicting the numeric response. We randomly divided the
dataset into a training set (80%) and a test set (20%).

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_13.png"
  title="**图10.13**："
>}}
Average-absolute error as a function of number of iterations
for the California housing data.

Figure 10.13 shows the average absolute error

$$\text{AAE} = E \|y - \hat{f}\_M(x)\| \tag{10.53}$$

as a function for number of iterations M on both the training data and test
data. The test error is seen to decrease monotonically with increasing M ,
more rapidly during the early stages and then leveling off to being nearly
constant as iterations increase. Thus, the choice of a particular value of M
is not critical, as long as it is not too small. This tends to be the case in
many applications. The shrinkage strategy (10.41) tends to eliminate the
problem of overfitting, especially for larger data sets.

The value of AAE after 800 iterations is 0.31. This can be compared to
that of the optimal constant predictor median{y i } which is 0.89. In terms of
more familiar quantities, the squared multiple correlation coefficient of this
model is R 2 = 0.84. Pace and Barry (1997) use a sophisticated spatial auto-
regression procedure, where prediction for each neighborhood is based on
median house values in nearby neighborhoods, using the other predictors as
covariates. Experimenting with transformations they achieved R 2 = 0.85,
predicting log Y . Using log Y as the response the corresponding value for
gradient boosting was R 2 = 0.86.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_14.png"
  title="**图10.14**："
>}}
Relative importance of the predictors for the California housing
data.

Figure 10.14 displays the relative variable importances for each of the
eight predictor variables. Not surprisingly, median income in the neigh-
borhood is the most relevant predictor. Longitude, latitude, and average
occupancy all have roughly half the relevance of income, whereas the others
are somewhat less influential.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_15.png"
  title="**图10.15**："
>}}
Partial dependence of housing value on the nonlocation vari-
ables for the California housing data. The red ticks at the base of the plot are
deciles of the input variables.

Figure 10.15 shows single-variable partial dependence plots on the most
relevant nonlocation predictors. Note that the plots are not strictly smooth.
This is a consequence of using tree-based models. Decision trees produce
discontinuous piecewise constant models (10.25). This carries over to sums
of trees (10.28), with of course many more pieces. Unlike most of the meth-
ods discussed in this book, there is no smoothness constraint imposed on
the result. Arbitrarily sharp discontinuities can be modeled. The fact that
these curves generally exhibit a smooth trend is because that is what is
estimated to best predict the response for this problem. This is often the
case.

The hash marks at the base of each plot delineate the deciles of the
data distribution of the corresponding variables. Note that here the data
density is lower near the edges, especially for larger values. This causes the
curves to be somewhat less well determined in those regions. The vertical
scales of the plots are the same, and give a visual comparison of the relative
importance of the different variables.

The partial dependence of median house value on median income is
monotonic increasing, being nearly linear over the main body of data. House
value is generally monotonic decreasing with increasing average occupancy,
except perhaps for average occupancy rates less than one. Median house
value has a nonmonotonic partial dependence on average number of rooms.
It has a minimum at approximately three rooms and is increasing both for
smaller and larger values.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_16.png"
  title="**图10.16**："
>}}
Partial dependence of house value on median age and aver-
age occupancy. There appears to be a strong interaction effect between these two
variables.

Median house value is seen to have a very weak partial dependence on
house age that is inconsistent with its importance ranking (Figure 10.14).
This suggests that this weak main effect may be masking stronger interac-
tion effects with other variables. Figure 10.16 shows the two-variable partial
dependence of housing value on joint values of median age and average oc-
cupancy. An interaction between these two variables is apparent. For values
of average occupancy greater than two, house value is nearly independent
of median age, whereas for values less than two there is a strong dependence
on age.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_17.png"
  title="**图10.17**："
>}}
Partial dependence of median house value on location in Cal-
ifornia. One unit is $100, 000, at 1990 prices, and the values plotted are relative
to the overall median of $180, 000.

Figure 10.17 shows the two-variable partial dependence of the fitted
model on joint values of longitude and latitude, displayed as a shaded
contour plot. There is clearly a very strong dependence of median house
value on the neighborhood location in California. Note that Figure 10.17 is
not a plot of house value versus location ignoring the effects of the other
predictors (10.49). Like all partial dependence plots, it represents the effect
of location after accounting for the effects of the other neighborhood and
house attributes (10.47). It can be viewed as representing an extra premium
one pays for location. This premium is seen to be relatively large near the
Pacific coast especially in the Bay Area and Los Angeles–San Diego re-
gions. In the northern, central valley, and southeastern desert regions of
California, location costs considerably less.

### 10.14.2 New Zealand Fish

Plant and animal ecologists use regression models to predict species pres-
ence, abundance and richness as a function of environmental variables.
Although for many years simple linear and parametric models were popu-
lar, recent literature shows increasing interest in more sophisticated mod-
els such as generalized additive models (Section 9.1, GAM), multivariate
adaptive regression splines (Section 9.4, MARS) and boosted regression
trees (Leathwick et al., 2005; Leathwick et al., 2006). Here we model the
presence and abundance of the Black Oreo Dory, a marine fish found in the
oceanic waters around New Zealand. 3

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_18.png"
  title="**图10.18**："
>}}
Map of New Zealand and its surrounding exclusive economic
zone, showing the locations of 17,000 trawls (small blue dots) taken between 1979
and 2005. The red points indicate trawls for which the species Black Oreo Dory
were present.

Figure 10.18 shows the locations of 17,000 trawls (deep-water net fishing,
with a maximum depth of 2km), and the red points indicate those 2353
trawls for which the Black Oreo was present, one of over a hundred species
regularly recorded. The catch size in kg for each species was recorded for
each trawl. Along with the species catch, a number of environmental mea-
surements are available for each trawl. These include the average depth of
the trawl ( AvgDepth ), and the temperature and salinity of the water. Since
the latter two are strongly correlated with depth, Leathwick et al. (2006)
derived instead TempResid and SalResid , the residuals obtained when these
two measures are adjusted for depth (via separate non-parametric regres-
sions). SSTGrad is a measure of the gradient of the sea surface temperature,
and Chla is a broad indicator of ecosytem productivity via satellite-image
measurements. SusPartMatter provides a measure of suspended particulate
matter, particularly in coastal waters, and is also satellite derived.

The goal of this analysis is to estimate the probability of finding Black
Oreo in a trawl, as well as the expected catch size, standardized to take
into account the effects of variation in trawl speed and distance, as well
as the mesh size of the trawl net. The authors used logistic regression
for estimating the probability. For the catch size, it might seem natural
to assume a Poisson distribution and model the log of the mean count,
but this is often not appropriate because of the excessive number of zeros.
Although specialized approaches have been developed, such as the zero-
inflated Poisson (Lambert, 1992), they chose a simpler approach. If Y is
the (non-negative) catch size,

$$E(Y|X) = E(Y | Y>0, X) \cdot \text{Pr}(Y>0 | X) \tag{10.54}$$

The second term is estimated by the logistic regression, and the first term
can be estimated using only the 2353 trawls with a positive catch.

For the logistic regression the authors used a gradient boosted model
(GBM) 4 with binomial deviance loss function, depth-10 trees, and a shrink-
age factor ν = 0.025. For the positive-catch regression, they modeled
log(Y ) using a GBM with squared-error loss (also depth-10 trees, but
ν = 0.01), and un-logged the predictions. In both cases they used 10-fold
cross-validation for selecting the number of terms, as well as the shrinkage
factor.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_19.png"
  title="**图10.19**："
>}}
The left panel shows the mean deviance as a function of the
number of trees for the GBM logistic regression model fit to the presence/absence
data. Shown are 10-fold cross-validation on the training data (and 1 × s.e. bars),
and test deviance on the test data. Also shown for comparison is the test deviance
using a GAM model with 8 df for each term. The right panel shows ROC curves
on the test data for the chosen GBM model (vertical line in left plot) and the
GAM model.

Figure 10.19 (left panel) shows the mean binomial deviance for the se-
quence of GBM models, both for 10-fold CV and test data. There is a mod-
est improvement over the performance of a GAM model, fit using smoothing
splines with 8 degrees-of-freedom (df) per term. The right panel shows the
ROC curves (see Section 9.2.5) for both models, which measures predictive
performance. From this point of view, the performance looks very simi-
lar, with GBM perhaps having a slight edge as summarized by the AUC
(area under the curve). At the point of equal sensitivity/specificity, GBM
achieves 91%, and GAM 90%.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_20.png"
  title="**图10.20**："
>}}
The top-left panel shows the relative influence computed from
the GBM logistic regression model. The remaining panels show the partial de-
pendence plots for the leading five variables, all plotted on the same scale for
comparison.

Figure 10.20 summarizes the contributions of the variables in the logistic
GBM fit. We see that there is a well-defined depth range over which Black
Oreo are caught, with much more frequent capture in colder waters. We do
not give details of the quantitative catch model; the important variables
were much the same.


{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_21.png"
  title="**图10.21**："
>}}
Geological prediction maps of the presence probability (left
map) and catch size (right map) obtained from the gradient boosted models.

All the predictors used in these models are available on a fine geographi-
cal grid; in fact they were derived from environmental atlases, satellite im-
ages and the like—see Leathwick et al. (2006) for details. This also means
that predictions can be made on this grid, and imported into GIS mapping
systems. Figure 10.21 shows prediction maps for both presence and catch
size, with both standardized to a common set of trawl conditions; since the
predictors vary in a continuous fashion with geographical location, so do
the predictions.

Because of their ability to model interactions and automatically select
variables, as well as robustness to outliers and missing data, GBM models
are rapidly gaining popularity in this data-rich and enthusiastic community.

### 10.14.3 Demographics Data

In this section we illustrate gradient boosting on a multiclass classifica-
tion problem, using MART. The data come from 9243 questionnaires filled
out by shopping mall customers in the San Francisco Bay Area (Impact
Resources, Inc., Columbus, OH). Among the questions are 14 concerning
demographics. For this illustration the goal is to predict occupation us-
ing the other 13 variables as predictors, and hence identify demographic
variables that discriminate between different occupational categories. We
randomly divided the data into a training set (80%) and test set (20%),
and used J = 6 node trees with a learning rate ν = 0.1.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_22.png"
  title="**图10.22**："
>}}
Error rate for each occupation in the demographics data.

Figure 10.22 shows the K = 9 occupation class values along with their
corresponding error rates. The overall error rate is 42.5%, which can be
compared to the null rate of 69% obtained by predicting the most numerous
class Prof/Man (Professional/Managerial). The four best predicted classes
are seen to be Retired , Student , Prof/Man , and Homemaker .

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_23.png"
  title="**图10.23**："
>}}
Relative importance of the predictors as averaged over all
classes for the demographics data.

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_24.png"
  title="**图10.24**："
>}}
Predictor variable importances separately for each of the four
classes with lowest error rate for the demographics data.

Figure 10.23 shows the relative predictor variable importances as aver-
aged over all classes (10.46). Figure 10.24 displays the individual relative
importance distributions (10.45) for each of the four best predicted classes.
One sees that the most relevant predictors are generally different for each
respective class. An exception is age which is among the three most relevant
for predicting Retired , Student , and Prof/Man .

{{< figure
  src="http://public.guansong.wang/eslii/ch10/eslii_fig_10_25.png"
  title="**图10.25**："
>}}
Partial dependence of the odds of three different occupations
on age, for the demographics data.

Figure 10.25 shows the partial dependence of the log-odds (10.52) on age
for these three classes. The abscissa values are ordered codes for respective
equally spaced age intervals. One sees that after accounting for the contri-
butions of the other variables, the odds of being retired are higher for older
people, whereas the opposite is the case for being a student. The odds of
being professional/managerial are highest for middle-aged people. These
results are of course not surprising. They illustrate that inspecting partial
dependences separately for each class can lead to sensible results.

[^1]: http://lib.stat.cmu.edu
[^2]: The models, data, and maps shown here were kindly provided by Dr John Leathwick of the National Institute of Water and Atmospheric Research in New Zealand, and Dr Jane Elith, School of Botany, University of Melbourne. The collection of the research trawl data took place from 1979–2005, and was funded by the New Zealand Ministry of Fisheries.
[^3]: Version 1.5-7 of package gbm in R, ver. 2.2.0.