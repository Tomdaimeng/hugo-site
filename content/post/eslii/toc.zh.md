+++
title = "统计学习基础：目录索引"
summary = "“统计学习基础”（ESL）一书的章节目录索引，随完成进度更新。"

date = 2018-08-27T15:18:10+08:00
lastmod = 2019-01-16T17:02:00+08:00
draft = false
math = true

authors = ["Butters"]

tags = ["2018"]
categories = ["统计学习基础（译注）"]

[header]
image = ""
caption = ""
preview = true
+++

另外可参考 Wei Ya 的翻译版本（[链接](https://esl.hohoweiya.xyz/)）。

1. [序言]({{< ref "/post/eslii/ch01/ch01_00.zh.md" >}})
2. 监督学习概述
  1. [引言]({{< ref "/post/eslii/ch02/ch02_01.zh.md" >}})
  2. [变量类型和术语]({{< ref "/post/eslii/ch02/ch02_02.zh.md" >}})
  3. [两个简单的预测方法：最小二乘和最近邻域]({{< ref "/post/eslii/ch02/ch02_03.zh.md" >}})
  4. [统计决策理论]({{< ref "/post/eslii/ch02/ch02_04.zh.md" >}})
  5. [局部方法中的高维度问题]({{< ref "/post/eslii/ch02/ch02_05.zh.md" >}})
  6. [统计模型、监督学习和函数逼近]({{< ref "/post/eslii/ch02/ch02_06.zh.md" >}})
  7. [有结构的回归模型]({{< ref "/post/eslii/ch02/ch02_07.zh.md" >}})
  8. [有约束的估计模型类型]({{< ref "/post/eslii/ch02/ch02_08.zh.md" >}})
  9. [模型选择和偏差方差权衡]({{< ref "/post/eslii/ch02/ch02_09.zh.md" >}})
3. 回归问题的线性方法
  1. [引言]({{< ref "/post/eslii/ch03/ch03_01.zh.md" >}})
  2. [线性回归模型和最小二乘]({{< ref "/post/eslii/ch03/ch03_02.zh.md" >}})
  3. [变量子集选择]({{< ref "/post/eslii/ch03/ch03_03.zh.md" >}})
  4. [收缩方法]({{< ref "/post/eslii/ch03/ch03_04.zh.md" >}})
  5. [衍生输入变量的方法]({{< ref "/post/eslii/ch03/ch03_05.zh.md" >}})
  6. [讨论：子集选择和收缩方法的比较]({{< ref "/post/eslii/ch03/ch03_06.zh.md" >}})
  7. [多输出变量的收缩和变量选择 :scream:]({{< ref "/post/eslii/ch03/ch03_07.zh.md" >}})
  8. [更多关于套索回归和类似的路径算法]({{< ref "/post/eslii/ch03/ch03_08.zh.md" >}})
  9. [计算量考量]({{< ref "/post/eslii/ch03/ch03_09.zh.md" >}})
4. 分类问题的线性方法
  1. [引言]({{< ref "/post/eslii/ch04/ch04_01.zh.md" >}})
  2. [对指示变量矩阵的线性回归]({{< ref "/post/eslii/ch04/ch04_02.zh.md" >}})
  3. [线性判别分析]({{< ref "/post/eslii/ch04/ch04_03.zh.md" >}})
  4. [对数几率回归（逻辑回归）]({{< ref "/post/eslii/ch04/ch04_04.zh.md" >}})
  5. [分离超平面]({{< ref "/post/eslii/ch04/ch04_05.zh.md" >}})
5. 基拓展和正则化
  1. [引言]({{< ref "/post/eslii/ch05/ch05_01.zh.md" >}})
  2. [分段多项式和样条]({{< ref "/post/eslii/ch05/ch05_02.zh.md" >}})
  3. [滤波和特征提取]({{< ref "/post/eslii/ch05/ch05_03.zh.md" >}})
  4. [平滑样条]({{< ref "/post/eslii/ch05/ch05_04.zh.md" >}})
  5. [平滑参数的自动选择]({{< ref "/post/eslii/ch05/ch05_05.zh.md" >}})
  6. [非参数对数几率回归]({{< ref "/post/eslii/ch05/ch05_06.zh.md" >}})
  7. [多维样条]({{< ref "/post/eslii/ch05/ch05_07.zh.md" >}})
  8. [正则化与再生核希尔伯特空间 :scream:]({{< ref "/post/eslii/ch05/ch05_08.zh.md" >}})
  9. [小波平滑]({{< ref "/post/eslii/ch05/ch05_09.zh.md" >}})
  10. Appendix: Computations for Splines
6. [核平滑方法]({{< ref "/post/eslii/ch06/ch06_00.zh.md" >}})
  1. [一维的核平滑器]({{< ref "/post/eslii/ch06/ch06_01.zh.md" >}})
  2. [核函数窗宽的选择]({{< ref "/post/eslii/ch06/ch06_02.zh.md" >}})
  3. [$\mathbb{R}^p$ 上的局部回归]({{< ref "/post/eslii/ch06/ch06_03.zh.md" >}})
  4. [ℝᵖ 上的结构化局部线性回归模型]({{< ref "/post/eslii/ch06/ch06_04.zh.md" >}})
  5. [局部似然和其他模型]({{< ref "/post/eslii/ch06/ch06_05.zh.md" >}})
  6. [核密度估计与分类问题]({{< ref "/post/eslii/ch06/ch06_06.zh.md" >}})
  7. [径向基函数与核函数]({{< ref "/post/eslii/ch06/ch06_07.zh.md" >}})
  8. [密度估计的混合模型与分类问题]({{< ref "/post/eslii/ch06/ch06_08.zh.md" >}})
  9. [计算量考量]({{< ref "/post/eslii/ch06/ch06_09.zh.md" >}})
7. 模型评估和选择
  1. [引言]({{< ref "/post/eslii/ch07/ch07_01.zh.md" >}})
  2. [偏差、方差和模型复杂度]({{< ref "/post/eslii/ch07/ch07_02.zh.md" >}})
  3. [偏差-方差分解]({{< ref "/post/eslii/ch07/ch07_03.zh.md" >}})
  4. [训练误差率中的乐观值]({{< ref "/post/eslii/ch07/ch07_04.zh.md" >}})
  5. [样本内预测误差的估计]({{< ref "/post/eslii/ch07/ch07_05.zh.md" >}})
  6. [有效参数个数]({{< ref "/post/eslii/ch07/ch07_06.zh.md" >}})
  7. [贝叶斯方法和 BIC]({{< ref "/post/eslii/ch07/ch07_07.zh.md" >}})
  8. [最小描述长度]({{< ref "/post/eslii/ch07/ch07_08.zh.md" >}})
  9. [万普尼克-泽范兰杰斯维度 :scream:]({{< ref "/post/eslii/ch07/ch07_09.zh.md" >}})
  10. [交叉验证]({{< ref "/post/eslii/ch07/ch07_10.zh.md" >}})
  11. [自助法]({{< ref "/post/eslii/ch07/ch07_11.zh.md" >}})
  12. [条件还是无条件期望测试误差？]({{< ref "/post/eslii/ch07/ch07_12.zh.md" >}})
8. 模型的推断和平均
  1. [引言]({{< ref "/post/eslii/ch08/ch08_01.zh.md" >}})
  2. [自助法和最大似然方法]({{< ref "/post/eslii/ch08/ch08_02.zh.md" >}})
  3. [贝叶斯方法]({{< ref "/post/eslii/ch08/ch08_03.zh.md" >}})
  4. [自助法与贝叶斯推断的关系 :scream:]({{< ref "/post/eslii/ch08/ch08_04.zh.md" >}})
  5. [最大期望（EM）算法]({{< ref "/post/eslii/ch08/ch08_05.zh.md" >}})
  6. [后验分布的马尔可夫链蒙特卡洛抽样]({{< ref "/post/eslii/ch08/ch08_06.zh.md" >}})
  7. [自助聚合（Bagging）]({{< ref "/post/eslii/ch08/ch08_07.zh.md" >}})
  8. [模型平均和堆叠（stacking）]({{< ref "/post/eslii/ch08/ch08_08.zh.md" >}})
  9. [随机搜索：Bumping]({{< ref "/post/eslii/ch08/ch08_09.zh.md" >}})
9. [加性模型、树模型和相关方法]({{< ref "/post/eslii/ch09/ch09_00.zh.md" >}})
  1. [广义加性模型]({{< ref "/post/eslii/ch09/ch09_01.zh.md" >}})
  2. [树结构模型]({{< ref "/post/eslii/ch09/ch09_02.zh.md" >}})
  3. [PRIM（耐心规则归纳方法）：凸块搜索]({{< ref "/post/eslii/ch09/ch09_03.zh.md" >}})
  4. [多元自适应回归样条（MARS）]({{< ref "/post/eslii/ch09/ch09_04.zh.md" >}})
  5. [层级混合专家]({{< ref "/post/eslii/ch09/ch09_05.zh.md" >}})
  6. [缺失数据]({{< ref "/post/eslii/ch09/ch09_06.zh.md" >}})
  7. [计算量考量]({{< ref "/post/eslii/ch09/ch09_07.zh.md" >}})
10. Boosting and Additive Trees
  1. [提升方法]()
  2. [Boosting Fits an Additive Model]()
  3. [Forward Stagewise Additive Modeling]()
  4. [Exponential Loss and AdaBoost]()
  5. [Why Exponential Loss?]()
  6. [Loss Functions and Robustness]
  7. ["Off-the-Shelf" Procedures for Data Mining]
  8. [Example: Spam Data]
  9. [Boosting Trees]
  10. [Numerical Optimization via Gradient Boosting]
  11. [Right-Sized Trees for Boosting]
  12. [Regularization]
  13. [Interpretation]
  14. [Illustrations]
11. Neural Networks
12. Support Vector Machines and Flexible Discriminants
13. Prototype Methods and Nearest-Neighbors
14. Unsupervised Learning
15. Random Forests
16. Ensemble Learning
17. Undirected Graphical Models
18. High-Dimensional Problems: p ≫ N
